{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numba\n",
    "import pandas as pd\n",
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise.model_selection import cross_validate"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "def get_most_popular():\n",
    "    data = pd.read_csv('data/data.csv')\n",
    "    top_ten = data.value_counts(subset=['Movie ID'])[:10]\n",
    "\n",
    "    ids = []\n",
    "    for element in list(top_ten.keys()):\n",
    "        ids.append(element[0])\n",
    "    return ids\n",
    "\n",
    "\n",
    "def get_highest_rated():\n",
    "    data = pd.read_csv('data/data.csv')\n",
    "    id_rating = data[['Movie ID', 'Rating']]\n",
    "    avg_ratings = id_rating.groupby(['Movie ID'], as_index=False).mean()\n",
    "    avg_ratings = avg_ratings.sort_values(by=['Rating'], ascending=False)[:10]\n",
    "    ids = list(avg_ratings['Movie ID'])\n",
    "    return ids\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "@numba.njit # decorator to parallelize computations for speed up\n",
    "def grad_U(Ui, Yij, Vj, reg, eta):\n",
    "    \"\"\"\n",
    "    Takes as input Ui (the ith row of U), a training point Yij, the column\n",
    "    vector Vj (jth column of V^T), reg (the regularization parameter lambda),\n",
    "    and eta (the learning rate).\n",
    "\n",
    "    Returns the gradient of the regularized loss function with\n",
    "    respect to Ui multiplied by eta.\n",
    "    \"\"\"\n",
    "    d_ui = reg * Ui - Vj * (Yij - np.dot(Ui, Vj))\n",
    "    return eta * d_ui\n",
    "\n",
    "@numba.njit\n",
    "def grad_V(Vj, Yij, Ui, reg, eta):\n",
    "    \"\"\"\n",
    "    Takes as input the column vector Vj (jth column of V^T), a training point Yij,\n",
    "    Ui (the ith row of U), reg (the regularization parameter lambda),\n",
    "    and eta (the learning rate).\n",
    "\n",
    "    Returns the gradient of the regularized loss function with\n",
    "    respect to Vj multiplied by eta.\n",
    "    \"\"\"\n",
    "    d_vj = reg * Vj - Ui * (Yij - np.dot(Ui, Vj))\n",
    "    return eta * d_vj\n",
    "\n",
    "@numba.njit\n",
    "def get_err(U, V, Y, reg=0.0):\n",
    "    \"\"\"\n",
    "    Takes as input a matrix Y of triples (i, j, Y_ij) where i is the index of a user,\n",
    "    j is the index of a movie, and Y_ij is user i's rating of movie j and\n",
    "    user/movie matrices U and V.\n",
    "\n",
    "    Returns the mean regularized squared-error of predictions made by\n",
    "    estimating Y_{ij} as the dot product of the ith row of U and the jth column of V^T.\n",
    "    \"\"\"\n",
    "    err = 0\n",
    "    for row in Y:\n",
    "      [i, j, Y_ij] = row\n",
    "      err += 0.5 * (Y_ij - np.dot(U[i-1], V[j-1]))**2\n",
    "    return err/len(Y)\n",
    "\n",
    "@numba.njit\n",
    "def train_model(M, N, K, eta, reg, Y, eps=0.0001, max_epochs=300):\n",
    "    \"\"\"\n",
    "    Given a training data matrix Y containing rows (i, j, Y_ij)\n",
    "    where Y_ij is user i's rating on movie j, learns an\n",
    "    M x K matrix U and N x K matrix V such that rating Y_ij is approximated\n",
    "    by (UV^T)_ij.\n",
    "\n",
    "    Uses a learning rate of <eta> and regularization of <reg>. Stops after\n",
    "    <max_epochs> epochs, or once the magnitude of the decrease in regularized\n",
    "    MSE between epochs is smaller than a fraction <eps> of the decrease in\n",
    "    MSE after the first epoch.\n",
    "\n",
    "    Returns a tuple (U, V, err) consisting of U, V, and the unregularized MSE\n",
    "    of the model.\n",
    "    \"\"\"\n",
    "    U = np.random.uniform(-0.5, 0.5, (M, K))\n",
    "    V = np.random.uniform(-0.5, 0.5, (N, K))\n",
    "    init_loss = get_err(U, V, Y)\n",
    "    prev_loss = 0\n",
    "    first_epoch_loss = 0\n",
    "    for epoch in range(max_epochs):\n",
    "      indices = np.random.permutation(len(Y))\n",
    "      for row in indices:\n",
    "        i, j, Y_ij = Y[row, 0], Y[row, 1], Y[row, 2]\n",
    "        U[i-1] -= grad_U(U[i-1], Y_ij, V[j-1], reg, eta)\n",
    "        V[j-1] -= grad_V(V[j-1], Y_ij, U[i-1], reg, eta)\n",
    "      curr_loss = get_err(U, V, Y)\n",
    "      if epoch == 0:\n",
    "        first_epoch_loss = init_loss - curr_loss\n",
    "      else:\n",
    "        if (prev_loss - curr_loss) <= eps * first_epoch_loss:\n",
    "          break\n",
    "      prev_loss = curr_loss\n",
    "    return (U, V, get_err(U, V, Y))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "train.columns = train.iloc[1]\n",
    "test.columns = test.iloc[1]\n",
    "train = train.drop(1)\n",
    "test = test.drop(1)\n",
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "Y_train = train.to_numpy(dtype=int)\n",
    "Y_test = test.to_numpy(dtype=int)\n",
    "\n",
    "M = max(max(Y_train[1:,0]), max(Y_test[1:,0])).astype(int) # users\n",
    "N = max(max(Y_train[1:,1]), max(Y_test[1:,1])).astype(int) # movies\n",
    "print(\"Factorizing with \", M, \" users, \", N, \" movies.\")\n",
    "K = 20\n",
    "\n",
    "reg = 0.0\n",
    "eta = 0.03 # learning rate\n",
    "E_in = []\n",
    "E_out = []\n",
    "\n",
    "# Use to compute Ein and Eout\n",
    "U,V, err = train_model(M, N, K, eta, reg, Y_train)\n",
    "E_in.append(err)\n",
    "E_out.append(get_err(U, V, Y_test))\n",
    "\n",
    "# plt.plot(K, E_in, label='$E_{in}$')\n",
    "# plt.plot(K, E_out, label='$E_{out}$')\n",
    "# plt.title('Error vs. K')\n",
    "# plt.xlabel('K')\n",
    "# plt.ylabel('Error')\n",
    "# plt.legend()\n",
    "# plt.savefig('Method_1.png')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Factorizing with  943  users,  1682  movies.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "reader = Reader()\n",
    "data = Dataset.load_from_df(train, reader)\n",
    "data_train  = data.build_full_trainset()\n",
    "algo = SVD(n_factors=25, n_epochs=300, biased=True, lr_all = 0.01, reg_all = 0.1)\n",
    "algo.fit(data_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7fc91925eeb0>"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "V = algo.qi.transpose()\n",
    "A = np.linalg.svd(V)[0]\n",
    "V_proj = np.dot(A[:, :2].transpose(), V)\n",
    "\n",
    "V_proj /= V_proj.std(axis=1).reshape(2, 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "752579dbebe7f4dfe7c1aa72eac13e23fc88be2cc1ea7ab14e1f8d69b2d97d12"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}